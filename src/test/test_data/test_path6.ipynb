{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook intended for trying out some techniques on the notebook 'Iris_Classification.ipynb' separately to avoid code conflictions with the stable version which is running. This was started mainly because I cannot get the same results as Randal S Olson's popular notebook. So, this notebook contains some of the analysis I did to get to know the reasons for non-reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem which I can't get my head around is the GridSearchCV function of sklearn.grid_search.GridSearchCV and also whether the problem is related to the cross-validation sets generated by sklearn.cross_validation.StratifiedKFold being random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length_cm</th>\n",
       "      <th>sepal_width_cm</th>\n",
       "      <th>petal_length_cm</th>\n",
       "      <th>petal_width_cm</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length_cm  sepal_width_cm  petal_length_cm  petal_width_cm  \\\n",
       "0              5.1             3.5              1.4             0.2   \n",
       "1              4.9             3.0              1.4             0.2   \n",
       "2              4.7             3.2              1.3             0.2   \n",
       "3              4.6             3.1              1.5             0.2   \n",
       "4              5.0             3.6              1.4             0.2   \n",
       "\n",
       "         class  \n",
       "0  Iris-setosa  \n",
       "1  Iris-setosa  \n",
       "2  Iris-setosa  \n",
       "3  Iris-setosa  \n",
       "4  Iris-setosa  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data = pd.read_csv('data/iris_data_clean.csv')\n",
    "iris_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]]\n",
      "['Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa']\n"
     ]
    }
   ],
   "source": [
    "inputs = iris_data[['sepal_length_cm', 'sepal_width_cm','petal_length_cm', 'petal_width_cm']].values\n",
    "targets = iris_data['class'].values\n",
    "\n",
    "print inputs[:5]\n",
    "print targets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_lists shape: (5, 10, 149)\n",
      "first_cv_list.shape: (10, 149)\n",
      "cv_lists_equality: [[ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " ..., \n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]]\n",
      "Are all the cv_lists same? : True\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# List of five different cross_validation splits\n",
    "cv_lists = []\n",
    "\n",
    "for i in xrange(5):\n",
    "    data_splits = []\n",
    "    skf = StratifiedKFold(n_splits = 10)\n",
    "    for train, test in skf.split(inputs, targets):\n",
    "        data_split = np.zeros(len(train) + len(test))\n",
    "        data_split[test] = 1\n",
    "        data_splits.append(data_split)    # append 10 folds\n",
    "    data_splits = np.array(data_splits)    # convert into a ndarray\n",
    "    cv_lists.append(data_splits)   # append current cv_split\n",
    "    \n",
    "\n",
    "cv_lists = np.array(cv_lists)\n",
    "print \"cv_lists shape:\", cv_lists.shape\n",
    "first_cv_list = cv_lists[0,:,:]\n",
    "print \"first_cv_list.shape:\", cv_lists[0].shape\n",
    "# Check if all the cv_lists are actually equal when shuffle = False\n",
    "bul = np.all(cv_lists == cv_lists[0], axis=0)\n",
    "print 'cv_lists_equality:', bul\n",
    "print 'Are all the cv_lists same? :', np.all(bul == True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So, it is confirmed that StratifiedKFold returns the same train-test split if <code>shuffle = False</code> (which is default). If <code>shuffle</code> is set to <code>True</code>, it would shuffle the data before splitting and that shuffling can be specified by <code>random_state</code> which if it is <code>None</code> uses standard numpy RNG (random number generator) and if is an <code>int</code> value, uses that as a seed to generate random numbers using a pseudo random generator. So, that's not messing up with the random results I got from GridSearchCV.\n",
    "\n",
    "So, it is indeed the decision tree which gets randomly initialized for every iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.973154362416\n",
      "Best params: {'max_features': 2, 'random_state': 6, 'criterion': 'gini', 'max_depth': 5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "            max_features=2, max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=6,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "parameter_grid = {'criterion': ['gini', 'entropy'],\n",
    "                  'random_state': range(20),\n",
    "                  'max_depth': [1, 2, 3, 4, 5],\n",
    "                  'max_features': [1, 2, 3, 4]}\n",
    "\n",
    "grid_search = GridSearchCV(dtc, param_grid = parameter_grid,\n",
    "                          cv = cv.split(inputs, targets))\n",
    "\n",
    "grid_search.fit(inputs, targets)\n",
    "\n",
    "print \"Best Score: {}\".format(grid_search.best_score_)\n",
    "print \"Best params: {}\".format(grid_search.best_params_)\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that I am sure that setting <code>random_state</code> to a fixed value will give me reproducible results but what should this fixed value be? Because, depending on this value, the <code>best_params_</code> found by <code>GridSearchCV</code> are different. So, this value does carry a lot of value, I think."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
