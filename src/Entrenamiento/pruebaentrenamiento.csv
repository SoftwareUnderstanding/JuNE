tipo;celda
Import;"from lxml import etree
from lxml import objectify
import pandas as pd
import re as re
from sqlalchemy import create_engine
from subprocess import Popen
#import lxml.usedoctest from http://lxml.de/objectify.html"
Import;"import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import math"
Import;"import numpy as np
import matplotlib.pyplot as plt
from matplotlib.backends.backend_pdf import PdfPages
%matplotlib inline"
Import;"import numpy as np
import ndio.remote.neurodata as neurodata
import ndio.ramon as ramon
import time
import ndio
import networkx as nx
start = time.time()

token_synapse = 'kasthuri2015_ramon_v4'
channel_synapse = 'synapses'

token_neurons = 'kasthuri2015_ramon_v4'
channel_neurons = 'neurons'

res = 3"
Import;"from IPython.display import HTML
HTML('''<script>
code_show=true; 
function code_toggle() {
 if (code_show){
 $('div.input').hide();
 } else {
 $('div.input').show();
 }
 code_show = !code_show
} 
$( document ).ready(code_toggle);
</script>
<i>The raw code for this IPython notebook is by default hidden for easier reading.
To toggle on/off the raw code, click </i> <a href=""javascript:code_toggle()"">here</a>.''')"
Import;"import pandas as pd
import numpy as np
import json
import urllib
import requests
import json"
Import;from machine_translation.evaluation import sentence_level_bleu, mteval_13
Import;"import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

# Make sure that caffe is on the python path:
caffe_root = '../'  # this file is expected to be in {caffe_root}/examples
import sys
sys.path.insert(0, caffe_root + 'python')

import caffe

plt.rcParams['figure.figsize'] = (10, 10)
plt.rcParams['image.interpolation'] = 'nearest'
plt.rcParams['image.cmap'] = 'gray'"
Import;"# Makes possible to show the output from matplotlib inline
%matplotlib inline
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import matplotlib

# Makes the figures in the PNG format:
# For more information see %config InlineBackend
%config InlineBackend.figure_formats=set([u'png'])

# plt.rcParams['figure.figsize'] = 5, 10

import numpy
import sys
import os
import scipy
from scipy import stats

import save_load_file as slf"
Import;from datetime import datetime
Import;"%matplotlib inline
import numpy as np
import scipy as sp
import matplotlib as mpl
import matplotlib.cm as cm
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from six.moves import range

# Setup Pandas
pd.set_option('display.width', 500)
pd.set_option('display.max_columns', 100)
pd.set_option('display.notebook_repr_html', True)

# Setup Seaborn
sns.set_style(""whitegrid"")
sns.set_context(""poster"")"
Import;"import tensorflow as tf
import math"
Import;import matplotlib.pyplot as plt
Import;"pip install rdflib
github_storage = ""https://raw.githubusercontent.com/FacultadInformatica-LinkedData/Curso2021-2022/master/Assignment4/course_materials"""
Import;"import pandas as pd
import numpy as np
import csv

from os import listdir
from os.path import isfile, join
#from torch.utils.tensorboard import SummaryWriter
import datajourney as DJ
import rdflib
import networkx.drawing, networkx.drawing.nx_agraph as ag

from pyrdf2vec import RDF2VecTransformer
from pyrdf2vec.embedders import Word2Vec
from pyrdf2vec.graphs import KG, Vertex
from pyrdf2vec.walkers import RandomWalker, Walker

import pygraphviz

from sklearn.naive_bayes import GaussianNB
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC, LinearSVC
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import RandomForestClassifier

import sklearn.metrics
from sklearn import tree
from sklearn import linear_model
from sklearn.model_selection import train_test_split
#
from transformers import AutoTokenizer, AutoModelForMaskedLM"
Import;"import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt "
Import;"import numpy as np

%matplotlib inline
import matplotlib.pyplot as plt

import pandas as pd"
Import;from pandas.tools.plotting import scatter_matrix
Import;"from collections import Counter
import numpy as np"
Import;from IPython.display import Image
Import;"import time
import sys
import numpy as np"
Import;"from bokeh.models import ColumnDataSource, LabelSet
from bokeh.plotting import figure, show, output_file
from bokeh.io import output_notebook"
Import;from sklearn.manifold import TSNE
Import;"import subprocess
import pandas as pd"
Import;"%matplotlib inline
import pandas as pd
import numpy as np
from sklearn.datasets import make_blobs
from sklearn.linear_model import LogisticRegression
import matplotlib.pyplot as plt"
Import;"from keras.applications.vgg16 import VGG16
from keras.models import Sequential, Model
from keras.layers.core import Flatten, Dense, Dropout, Reshape, Lambda
from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D,UpSampling2D
from keras.optimizers import SGD
from keras.regularizers import l2
from keras.layers import merge, Input
import numpy as np
from keras.callbacks import ModelCheckpoint, Callback, CSVLogger, LearningRateScheduler
from scipy.misc import imshow, imread, imresize, imsave"
Import;%pylab inline
Import;"from scipy.io import loadmat
from MP import progress_bar
from glob import glob
import pandas as pd
import time,os
from matplotlib import gridspec
gs=gridspec.GridSpec
uet=progress_bar.update_elapsed_time

from MP.lib import mpl_lib
from MP.lib.mpl_lib import rm_all_lab as ral
from MP.lib.mpl_lib import tune_xy_lim as txl
from matplotlib.colors import LogNorm

from MP.mat import mech"
Import;import requests
Import;"import tensorflow as tf
import numpy as np"
Import;"from lxml import etree
from lxml import objectify
import pandas as pd
import re as re
from sqlalchemy import create_engine
from subprocess import Popen
#import lxml.usedoctest from http://lxml.de/objectify.html"
Import;"from lxml import etree
from lxml import objectify
import pandas as pd
import re as re
from sqlalchemy import create_engine
from subprocess import Popen
#import lxml.usedoctest from http://lxml.de/objectify.html"
Import;from sklearn import datasets
Visualizacion;"fig = plt.figure()
ax = plt.axes()
plt.grid()
plt.show()"
Visualizacion;"plt.figure(figsize=(15,15)) #Ploteamos el panel deseado con las primeras seis iteraciones.
for i in range(0,6):
    points = koch(i,TOTALWIDTH,(0,10))
    plt.subplot(2,3,i+1,aspect='equal')
    plt.plot(np.asarray(points)[:,0],np.asarray(points)[:,1],color='red')
    plt.axis('off')
plt.show()"
Visualizacion;"alphadeg = np.linspace(0.01, 22.5, 100)
alpha = np.deg2rad(alphadeg)
e = 1 - 2*(1 - np.cos(alpha))/(1 - np.cos(alpha)**2)
e = np.abs(e*100)
plt.plot(alphadeg, e)
plt.title('One-dimensional approximation error.')
plt.xlabel('$\\alpha\>\>[^\circ]$', fontsize=14)
plt.ylabel(r'$|e|\>\>[\%]$', fontsize=14)
plt.savefig('tex/figs/q1.pdf')
plt.show()"
Visualizacion;"s = nd.get_ramon(token_synapse, channel_synapse, id_synapse[3])
print s.segments[0]
vars(s)"
Visualizacion;"import matplotlib.pyplot as plt
%matplotlib inline  

nx.draw_networkx(G, width=1, node_size = 100, with_labels=False, pos=nx.fruchterman_reingold_layout(G))#random_layout(G))# fruchterman_reingold_layout(G))
plt.show()
nx.draw_networkx(G, width=1, node_size = 100, with_labels=False, pos=nx.random_layout(G))#random_layout(G))
plt.show()"
Visualizacion;print '{} seconds elapsed.'.format(time.time()-start)
Visualizacion;"fig, ax = plt.subplots(2,2, figsize=(12, 7))
fig.suptitle(""Result for $q_l$"", size=16)
ax[0, 0].hist(actual_test_values[:, 0], bins=np.linspace(0, 0.02, 40))
ax[0, 0].set_title('Testing actual values')

ax[0, 1].hist(modeled_test_values[:, 0], bins=np.linspace(0, 0.02, 40))
ax[0, 1].set_title('Testing modeled values')

ax[1, 0].hist(actual_training_values[:, 0], bins=np.linspace(0, 0.02, 40))
ax[1, 0].set_title('Training actual values')

ax[1, 1].hist(modeled_training_values[:, 0], bins=np.linspace(0, 0.02, 40))
ax[1, 1].set_title('Training modeled values')
plt.show()"
Visualizacion;"import pandas as pd
df = pd.read_csv(""weather.csv"")
df"
Visualizacion;"melted = pd.melt(df, id_vars=[""day""], var_name='city', value_name='temperature')
melted"
Visualizacion;"# objective function & boundaries
# pprint(mfba.objective)
df = fbc.cobra_reaction_info(model)
print(df)
print(""reactions:"", len(model.reactions))
print(""metabolites:"", len(model.metabolites))
print(""genes:"", len(model.genes))"
Visualizacion;"ex_idx = df.index.str.contains('^EX_')
df[ex_idx]"
Visualizacion;"import geopandas as gpd
from geopandas import GeoDataFrame, read_file
zipcodes = gpd.GeoDataFrame.from_file('data/ZIP_CODE_040114/ZIP_CODE_040114.shp')
zipcodes = zipcodes.to_crs(epsg=4326) # apparently required by CartoBD, according to http://gis.stackexchange.com/questions/159681/geopandas-cant-save-geojson
zipcodes.columns"
Visualizacion;"for idx, diff in most_improved[:3000]:
    source_len = len(source_lines[idx].split())
    target_len = len(ref_lines[idx].split())
    edit_distance = get_editdistance(baseline_hyp_lines[idx], ref_lines[idx])
#     print(edit_distance)
    if (target_len > 10
    and target_len < 30
    and len(constraints[idx]) > 1
    and edit_distance >= 0.5):
        print(u'S1: {} S2: {}'.format(baseline_scores[idx], constrained_scores[idx]))
        print(u'Source: {}'.format(source_lines[idx]))
        print(u'Hyp1: {}'.format(baseline_hyp_lines[idx]))
        print(u'Constraints: {}'.format(constraints[idx]))
        print(u'Hyp2: {}'.format(constrained_hyp_lines[idx]))
        print(u'Ref: {}\n'.format(ref_lines[idx]))"
Visualizacion;"# index four is the center crop
image = net.blobs['data'].data[4].copy()
image -= image.min()
image /= image.max()
showimage(image.transpose(1, 2, 0))"
Visualizacion;"dfid = pd.DataFrame()
for field in list_fields:
    #for variable in field.getchildren():
    for variable in field.iter(""variable""):
        #print(variable.attrib['id'],variable.attrib['name'])
        dfid = dfid.append(pd.Series([variable.attrib['id'].replace('_',''),variable.attrib['name'],'variable']),ignore_index=True)
    for loop in field.iter(""loop""):
        for class_ in loop.iter(""class""):
            for fields in class_.iter(""fields""):
                for variable in fields.iter(""variable""):
        #print(loop.attrib['id'],loop.attrib['name'])
                    dfid = dfid.append(pd.Series([variable.attrib['id'].replace('_',''),loop.attrib['name'],'loop']),ignore_index=True)
dfid.columns=['id','name','type']"
Visualizacion;"filters = net.params['conv1'][0].data
vis_square(filters.transpose(0, 2, 3, 1))"
Visualizacion;"df = pd.DataFrame()
for variable in list_variables:
    for categories in variable.getchildren():
        for category in categories.iter(""category""):
            for labels in category.iter(""labels""):
                for element in labels.iter(""text""):
                    if element.attrib['{http://www.w3.org/XML/1998/namespace}lang']=='de-DE':
                        #print(variable.attrib['name'],category.attrib['name'], element.text)
                        df = df.append(pd.Series([variable.attrib['id'].replace('_',''),category.attrib['id'],variable.attrib['name'],category.attrib['name'], element.text]),ignore_index=True)
df.columns=['DimID','ID','DimVar',  'DimVal','Label']"
Visualizacion;"dfx = pd.DataFrame()
for categories_ in list_categories:
#    for categories_ in categories_.getchildren():
    for category in categories_.iter(""category""):
        for labels in category.iter(""labels""):
            for element in labels.iter(""text""):
                if element.attrib['{http://www.w3.org/XML/1998/namespace}lang']=='de-DE':
                    #print(variable.attrib['name'],category.attrib['name'], element.text)
                    dfx = dfx.append(pd.Series([variable.attrib['id'].replace('_',''),category.attrib['id'],categories_.attrib['name'],category.attrib['name'], element.text]),ignore_index=True)
dfx.columns=['DimID','ID','DimVar',  'DimVal','Label']"
Visualizacion;df.plot()
Visualizacion;df.info()
Visualizacion;df.describe()
Visualizacion;_ = df.plot(kind='scatter', x='Height', y='Weight')
Visualizacion;"df['Gendercolor'] = df['Gender'].map({'Male': 'blue', 'Female': 'red'})
df.head()"
Visualizacion;"df.plot(kind='scatter', 
        x='Height',
        y='Weight',
        c=df['Gendercolor'],
        alpha=0.3,
        title='Male & Female Populations')"
Visualizacion;"print(""labels.txt \t : \t reviews.txt\n"")
pretty_print_review_and_label(2137)
pretty_print_review_and_label(12816)
pretty_print_review_and_label(6267)
pretty_print_review_and_label(21934)
pretty_print_review_and_label(5297)
pretty_print_review_and_label(4998)"
Visualizacion;"print(""Pos-to-neg ratio for 'the' = {}"".format(pos_neg_ratios[""the""]))
print(""Pos-to-neg ratio for 'amazing' = {}"".format(pos_neg_ratios[""amazing""]))
print(""Pos-to-neg ratio for 'terrible' = {}"".format(pos_neg_ratios[""terrible""]))"
Visualizacion;"print(""Pos-to-neg ratio for 'the' = {}"".format(pos_neg_ratios[""the""]))
print(""Pos-to-neg ratio for 'amazing' = {}"".format(pos_neg_ratios[""amazing""]))
print(""Pos-to-neg ratio for 'terrible' = {}"".format(pos_neg_ratios[""terrible""]))"
Visualizacion;Image(filename='sentiment_network_2.png')
Visualizacion;"hist, edges = np.histogram(list(map(lambda x:x[1],pos_neg_ratios.most_common())), density=True, bins=100, normed=True)

p = figure(tools=""pan,wheel_zoom,reset,save"",
           toolbar_location=""above"",
           title=""Word Positive/Negative Affinity Distribution"")
p.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:], line_color=""#555555"")
show(p)"
Visualizacion;"hist, edges = np.histogram(list(map(lambda x:x[1],frequency_frequency.most_common())), density=True, bins=100, normed=True)

p = figure(tools=""pan,wheel_zoom,reset,save"",
           toolbar_location=""above"",
           title=""The frequency distribution of the words in our corpus"")
p.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:], line_color=""#555555"")
show(p)"
Visualizacion;Image(filename='sentiment_network_sparse.png')
Visualizacion;"p = subprocess.Popen(['C:/Program Files (x86)/biogeme-2.4/biogeme-2.4/biogeme.exe', model_name,model_data], shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
for line in p.stdout.readlines():
    print (line),
retval = p.wait()"
Visualizacion;"p = subprocess.Popen(['C:/Program Files (x86)/biogeme-2.4/biogeme-2.4/biosim.exe', model_name+'_res',model_data], shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
for line in p.stdout.readlines():
    print (line),
retval = p.wait()"
Visualizacion;"simres = pd.read_csv(model_name+'_res.enu',sep='\t')
simres.head()"
Visualizacion;simres.groupby('Choice_Id')['Accuracy'].mean()
Visualizacion;simres.groupby('Choice_Id')['ModeAccurate'].mean()
Visualizacion;simres.groupby(['Choice_Id','Mode_Prediction']).size()
Visualizacion;scatter(X,y)
Visualizacion;"scatter(X,y)
plot_separator(logreg.predict)"
Visualizacion;"data = np.load(""newdataset1.npz"")
sxtrain1 = data[""xtrain""]
sytrain1 = data[""ytrain""]

#sxtrain1 = np.load('xlabeled.npy')
#sytrain1 = np.load('ylabeled.npy')

print(sxtrain1.shape)
print(sxtrain1.dtype)
print(sytrain1.shape)
print(sytrain1.dtype)



#print(len(temp1.layers))
#temp1.summary()"
Visualizacion;"sxtrain2 = sxtrain1[:1049,:,:,:]
sytrain2 = sytrain1[:1049,:,:]
sxtest2 = sxtrain1[1049:,:,:,:]
sytest2 = sytrain1[1049:,:,:]
print(sxtrain2.shape)
print(sxtrain2.dtype)
print(sytrain2.shape)
print(sytrain2.dtype)
print(sxtest2.shape)
print(sxtest2.dtype)
print(sytest2.shape)
print(sytest2.dtype)"
Visualizacion;"xt1 = sxtrain2[0]
cimg1 = np.zeros((240,320,3),dtype=np.uint8)
cimg1[:,:,0] = xt1[0,:,:]
cimg1[:,:,1] = xt1[1,:,:]
cimg1[:,:,2] = xt1[2,:,:]

plt.imshow(cimg1)
plt.show()
plt.imshow(sytrain2[0])
plt.show()"
Visualizacion;sytrain2.dtype
Visualizacion;"for i in range(0,len(temp1.layers)-5):
    temp1.layers[i].trainable = False
temp1.summary()"
Visualizacion;"for i in range(len(model2.layers)):
    model2.layers[i].trainable = False
    
model2.summary()"
Visualizacion;"preds1 = model2.predict(sxtrain2,verbose=1)
print(preds1.shape)
plt.imshow(preds1[0])
plt.show()"
Visualizacion;"print(preds[0])
ans1 = imresize(preds[0],(480,640))
print(ans1.shape)
plt.imshow(ans1)
plt.show()"
Visualizacion;predsfine[1].shape
Visualizacion;"print(len(f1.layers))
temp12 = f1.get_layer(""convolution2d_1"")
#f3 = temp12.get_weights()
print(f1.layers[24].output_shape)
print(f1.layers[26].output_shape)
print(f1.layers[27].output_shape)
print(f1.layers[29].output_shape)
print(f1.layers[30].output_shape)
print(f1.layers[27].output)
c1 = f1.get_layer(""lambda_2"")
print(c1.output_shape)
print(f1.layers[25].input_shape)

#print(np.max(f3[0]))
#print(np.min(f3[0]))"
Visualizacion;"print(gt1[0][63])
print(np.max(gt1[0][63]))
print(np.min(gt1[0][63]))"
